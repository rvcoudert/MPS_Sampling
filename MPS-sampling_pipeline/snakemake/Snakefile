# Copyright or © or Copr.
# Rémi-Vinh COUDERT, Céline BROCHIER-ARMANET (2023-02-14)
# 
# rv.coudert@gmail.com
# celine.brochier-armanet@univ-lyon1.fr
# 
# This software is a computer program whose purpose is to sample representative genomes from large datasets.
# 
# This software is governed by the [CeCILL|CeCILL-B|CeCILL-C] license under French law and
# abiding by the rules of distribution of free software.  You can  use, 
# modify and/ or redistribute the software under the terms of the [CeCILL|CeCILL-B|CeCILL-C]
# license as circulated by CEA, CNRS and INRIA at the following URL
# "http://www.cecill.info". 
# 
# As a counterpart to the access to the source code and  rights to copy,
# modify and redistribute granted by the license, users are provided only
# with a limited warranty  and the software's author,  the holder of the
# economic rights,  and the successive licensors  have only  limited
# liability. 
# 
# In this respect, the user's attention is drawn to the risks associated
# with loading,  using,  modifying and/or developing or reproducing the
# software by the user in light of its specific status of free software,
# that may mean  that it is complicated to manipulate,  and  that  also
# therefore means  that it is reserved for developers  and  experienced
# professionals having in-depth computer knowledge. Users are therefore
# encouraged to load and test the software's suitability as regards their
# requirements in conditions enabling the security of their systems and/or 
# data to be ensured and,  more generally, to use and operate it in the 
# same conditions as regards security. 
# 
# The fact that you are presently reading this means that you have had
# knowledge of the [CeCILL|CeCILL-B|CeCILL-C] license and that you accept its terms.


## Snakefile
##  Python script to manage the Snakemake pipeline.

## Get config variables.
# Verbose, to be or not to be.
if "verbose" in config.keys():
    verbose = config["verbose"]
else:
    verbose = False

# Display the current directory.
if verbose:
    # Print current directory.
    print("Current Directory : " + os.getcwd())

# Set input directory.
if "input_directory" in config.keys():
    input_directory = config["input_directory"]
else:
    input_directory = "input/"
    if verbose:
        print("Input directory is not defined in the snakemake command.\n\tSet to default input_directory=\"input\".")

# Set LinclustTemp directory.
if "LinclustTemp_directory" in config.keys():
    LinclustTemp_directory = config["LinclustTemp_directory"]
else:
    LinclustTemp_directory = "LinclustTemp"
    if verbose:
        print("LinclustTemp directory is not defined in the snakemake command.\n\tSet to default LinclustTemp_directory=\"LinclustTemp\".")

# If it is not existed yet, create the LinclustTemp directory.
if not os.path.exists(LinclustTemp_directory):
   os.makedirs(LinclustTemp_directory)
   if verbose:
       print("Creation of directory:", LinclustTemp_directory)

# Set output directory.
if "output_directory" in config.keys():
    output_directory = config["output_directory"]
else:
    output_directory = "output/"
    if verbose:
        print("Output directory is not defined in the snakemake command.\n\tSet to default output_directory=\"input\".")

# Set e_values.
if "e_values" in config.keys():
    e_values = config["e_values"]
else:
    e_values = 0.00001
    if verbose:
        print("E-values (Linclust) are not defined in the snakemake command.\n\tSet to default e_values=10e-6.")


# Set coverage mode.
if "cov_modes" in config.keys():
    cov_modes = config["cov_modes"]
else:
    cov_modes = 0
    if verbose:
        print("Coverage modes (Linclust) are not defined in the snakemake command.\n\tSet to default cov_modes=0.")

# Set minimum coverage.
if "min_covs" in config.keys():
    min_covs = config["min_covs"]
else:
    min_covs = 0.8
    if verbose:
        print("Minimum coverages (Linclust) are not defined in the snakemake command.\n\tSet to default min_covs=0.8.")

# Set minimum sequence identity.
if "min_seq_ids" in config.keys():
    min_seq_ids = config["min_seq_ids"]
else:
    min_seq_ids = 0.6
    if verbose:
        print("Minimum sequence identites (Linclust) are not defined in the snakemake command.\nSet to default min_seq_ids=0.6.")
        
# Set ascending order or descending order for the sorting strategy of the Lin-clustering matrix.
# if "ascending_order" in config.keys():
#     ascending_order = config["ascending_order"]
# else:
#     ascending_order = False
#     if verbose:
#         print("Ascending order (Lin-clustering matrix) is not defined in the snakemake command.\nSet to default ascending_order=False.")
ascending_order = True

# Set minimum number of Lin-clusters for the hierarchical clustering with complete linkage.
if "deltas" in config.keys():
    deltas = config["deltas"]
else:
    deltas = 0.5
    if verbose:
        print("Minimum similarity deltas (complete-linkage) are not defined in the snakemake command.\nSet to default deltas=0.5.")



## Set important directories.
# Set directory of fasta files.
input_fasta_directory = input_directory + "fasta/"
# Set directory of input stats.
input_stats_directory = output_directory + "0.input_stats/"
# Set directory of Linclust data.
Linclust_directory = output_directory + "1.Linclust/"
# Set directory of Lin-cluster matrix.
Linclustering_matrix_directory = output_directory + "2_1.2_2.Linclustering_matrix/"
# Set directory of Lin-combination matrix.
Lincombination_matrix_directory = output_directory + "2_3.Lincombination_matrix/"
# Set directory of dissimilarity matrix.
dissimilarity_matrix_directory = output_directory + "3_1.dissimilarity_matrix/"
# Set directory of hierarchical clustering.
hierarchical_clustering_directory = output_directory + "3_2.hierarchical_clustering/"
# Set directory of MPS-clusters.
MPS_clusters_directory = output_directory + "3_3.MPS_clusters/"
# Set directory of genome cascading links.
genome_cascading_links_directory = output_directory + "3_4.genome_cascading_links/"
# Set directory of MPS-representatives and MPS-links.
MPS_results_directory = output_directory + "4.MPS_results_directory/"


# List protein families.
list_proteinFamilies = os.listdir(input_fasta_directory)
list_proteinFamilies = sorted(list(list_proteinFamilies))
if verbose:
    print("Found " + str(len(list_proteinFamilies)) + " protein families among the input files:")
    print(list_proteinFamilies)


# General rule : List requested outputs.
rule all:
    input:
        # Step 0: Check integrity and compute input stats.
        input_stats = input_stats_directory + "input_stats.csv",
        # Step 1: Build Lin-clusters whithin protein families.
        # Lincluster_files = expand(Linclust_directory + "e_value_{e_value}_cov_mode_{cov_mode}_min_cov_{min_cov}_min_seq_id_{min_seq_id}/{proteinFamily}/{proteinFamily}.fasta_cluster.tsv", e_value=e_values, cov_mode=cov_modes, min_cov=min_covs, min_seq_id=min_seq_ids, proteinFamily=list_proteinFamilies)
        # # Steps 2-1, 2-2: Build Lin-cluster matrix.
        # Linclustering_matrix = expand(Linclustering_matrix_directory + "e_value_{e_value}_cov_mode_{cov_mode}_min_cov_{min_cov}_min_seq_id_{min_seq_id}/Linclustering_matrix.csv", e_value=e_values, cov_mode=cov_modes, min_cov=min_covs, min_seq_id=min_seq_ids)
        # # Step 2-3: Build the Lin-combination matrix.
        # Lincombination_matrix = expand(Lincombination_matrix_directory + "e_value_{e_value}_cov_mode_{cov_mode}_min_cov_{min_cov}_min_seq_id_{min_seq_id}/Lincombination_matrix.csv", e_value=e_values, cov_mode=cov_modes, min_cov=min_covs, min_seq_id=min_seq_ids)
        # # Step 3-1: Compute dissimilarity matrix.
        # dissimilarity_matrix = expand(dissimilarity_matrix_directory + "e_value_{e_value}_cov_mode_{cov_mode}_min_cov_{min_cov}_min_seq_id_{min_seq_id}/dissimilarity_matrix.RDS", e_value=e_values, cov_mode=cov_modes, min_cov=min_covs, min_seq_id=min_seq_ids)
        # # Step 3-2: Compute hierarchical clustering.
        # hierarchical_clustering = expand(hierarchical_clustering_directory + "e_value_{e_value}_cov_mode_{cov_mode}_min_cov_{min_cov}_min_seq_id_{min_seq_id}/hierarchical_clustering.RDS", e_value=e_values, cov_mode=cov_modes, min_cov=min_covs, min_seq_id=min_seq_ids)
        # # Step 3-3: Build MPS-clusters.
        # Lincomb_MPS_clusters_links = expand(MPS_clusters_directory + "e_value_{e_value}_cov_mode_{cov_mode}_min_cov_{min_cov}_min_seq_id_{min_seq_id}/delta_{delta}/Lincomb_MPS_cluster_links.csv", e_value=e_values, cov_mode=cov_modes, min_cov=min_covs, min_seq_id=min_seq_ids, delta=deltas),
        # # Step 3-4: Gather genome cascading links.
        # genome_cascading_links = expand(genome_cascading_links_directory + "e_value_{e_value}_cov_mode_{cov_mode}_min_cov_{min_cov}_min_seq_id_{min_seq_id}/delta_{delta}/genome_cascading_links.csv", e_value=e_values, cov_mode=cov_modes, min_cov=min_covs, min_seq_id=min_seq_ids, delta=deltas),
        # # Step 4: Select MPS-representatives.
        MPS_representatives = expand(MPS_results_directory + "e_value_{e_value}_cov_mode_{cov_mode}_min_cov_{min_cov}_min_seq_id_{min_seq_id}/delta_{delta}/MPS_representatives.csv", e_value=e_values, cov_mode=cov_modes, min_cov=min_covs, min_seq_id=min_seq_ids, delta=deltas)


# Prefer fasta preparation over sequence clustering.
ruleorder: check_integrity > Linclust


## Step 0: Check integrity and compute input stats.


# Check data integrity and compute basic stats.
rule check_integrity:
    input:
        fasta_files = expand(input_fasta_directory + "{proteinFamily}/{proteinFamily}.fasta", proteinFamily=list_proteinFamilies),
        genome_index = input_directory + "genome_index.csv"
    output:
        input_stats = input_stats_directory + "input_stats.csv"
    params:
        cores = workflow.cores
    conda:
        "envs/R_env.yaml"
    script:
        "scripts/0.check_integrity.R"


## Step 1: Build Lin-clusters whithin protein families.


# Launch Linclust for each protein family.
rule Linclust:
    input:
        input_fasta_directory + "{proteinFamily}/{proteinFamily}.fasta"
    output:
        Linclust_directory + "e_value_{e_value}_cov_mode_{cov_mode}_min_cov_{min_cov}_min_seq_id_{min_seq_id}/{proteinFamily}/{proteinFamily}.fasta_all_seqs.fasta",
        Linclust_directory + "e_value_{e_value}_cov_mode_{cov_mode}_min_cov_{min_cov}_min_seq_id_{min_seq_id}/{proteinFamily}/{proteinFamily}.fasta_rep_seq.fasta",
        Linclust_directory + "e_value_{e_value}_cov_mode_{cov_mode}_min_cov_{min_cov}_min_seq_id_{min_seq_id}/{proteinFamily}/{proteinFamily}.fasta_cluster.tsv"
    conda:
         "envs/Linclust_env.yaml"
    shell:
        "mmseqs easy-cluster -e {wildcards.e_value} --cov-mode {wildcards.cov_mode} -c {wildcards.min_cov}  --min-seq-id {wildcards.min_seq_id} {input} " + Linclust_directory + "e_value_{wildcards.e_value}_cov_mode_{wildcards.cov_mode}_min_cov_{wildcards.min_cov}_min_seq_id_{wildcards.min_seq_id}/{wildcards.proteinFamily}/{wildcards.proteinFamily}.fasta " + LinclustTemp_directory + "/e_value_{wildcards.e_value}_cov_mode_{wildcards.cov_mode}_min_cov_{wildcards.min_cov}_min_seq_id_{wildcards.min_seq_id}_{wildcards.proteinFamily}"


## Steps 2-1, 2-2: Build Lin-cluster matrix.


# Label and merge Lin-clusters within protein families to build a single Lin-cluster matrix.
rule build_Linclustering_matrix:
    input:
    # Double brackets to not expand other wildcards.
        Lincluster_files = expand(Linclust_directory + "e_value_{{e_value}}_cov_mode_{{cov_mode}}_min_cov_{{min_cov}}_min_seq_id_{{min_seq_id}}/{proteinFamily}/{proteinFamily}.fasta_cluster.tsv", proteinFamily=list_proteinFamilies)
    output:
        Linclustering_matrix = Linclustering_matrix_directory + "e_value_{e_value}_cov_mode_{cov_mode}_min_cov_{min_cov}_min_seq_id_{min_seq_id}/Linclustering_matrix.csv"
    params:
        cores = workflow.cores,
        ascending_order = ascending_order
    conda:
        "envs/R_env.yaml"
    script:
        "scripts/2_1.2_2.build_Lin-clustering_matrix.R"


## Step 2-3: Build Lin-combination matrix.


# Remove redundant Lin-combinations to build a Lin-combination matrix.
rule build_Lincombination_matrix:
    input:
        Linclustering_matrix = Linclustering_matrix_directory + "e_value_{e_value}_cov_mode_{cov_mode}_min_cov_{min_cov}_min_seq_id_{min_seq_id}/Linclustering_matrix.csv"
    output:
        Lincombination_matrix = Lincombination_matrix_directory + "e_value_{e_value}_cov_mode_{cov_mode}_min_cov_{min_cov}_min_seq_id_{min_seq_id}/Lincombination_matrix.csv",
        gen_Lincomb_links = Lincombination_matrix_directory + "e_value_{e_value}_cov_mode_{cov_mode}_min_cov_{min_cov}_min_seq_id_{min_seq_id}/gen_Lincomb_links.csv"
    params:
        cores = workflow.cores
    conda:
        "envs/R_env.yaml"
    script:
        "scripts/2_3.build_Lin-combination_matrix.R"


## Step 3-1a: Compute dissimilarity matrix.


# Compute the dissimilarity matrix between all Lincombinations.
rule compute_dissimilarity_matrix:
    input:
        Lincombination_matrix = Lincombination_matrix_directory + "e_value_{e_value}_cov_mode_{cov_mode}_min_cov_{min_cov}_min_seq_id_{min_seq_id}/Lincombination_matrix.csv"
    output:
        dissimilarity_matrix_raw = dissimilarity_matrix_directory + "e_value_{e_value}_cov_mode_{cov_mode}_min_cov_{min_cov}_min_seq_id_{min_seq_id}/dissimilarity_matrix_raw.RDS"
    params:
        cores = workflow.cores
    conda:
        "envs/R_env.yaml"
    script:
        "scripts/3_1a.compute_dissimilarity_matrix.R"


## Step 3-1b: Convert dissimilarity matrix.


# Convert the dissimilarity matrix between all Lincombinations.
rule convert_dissimilarity_matrix:
    input:
        dissimilarity_matrix_raw = dissimilarity_matrix_directory + "e_value_{e_value}_cov_mode_{cov_mode}_min_cov_{min_cov}_min_seq_id_{min_seq_id}/dissimilarity_matrix_raw.RDS"
    output:
        dissimilarity_matrix = dissimilarity_matrix_directory + "e_value_{e_value}_cov_mode_{cov_mode}_min_cov_{min_cov}_min_seq_id_{min_seq_id}/dissimilarity_matrix.RDS"
    params:
        cores = workflow.cores
    conda:
        "envs/R_env.yaml"
    script:
        "scripts/3_1b.convert_dissimilarity_matrix.R"


## Step 3-2: Compute hierarchical clustering.


# Compute hierarchical clustering of all Lincombinations.
rule compute_hierarchical_clustering:
    input:
        dissimilarity_matrix = dissimilarity_matrix_directory + "e_value_{e_value}_cov_mode_{cov_mode}_min_cov_{min_cov}_min_seq_id_{min_seq_id}/dissimilarity_matrix.RDS"
    output:
        hierachical_clustering = hierarchical_clustering_directory + "e_value_{e_value}_cov_mode_{cov_mode}_min_cov_{min_cov}_min_seq_id_{min_seq_id}/hierarchical_clustering.RDS"
    params:
        cores = workflow.cores
    conda:
        "envs/R_env.yaml"
    script:
        "scripts/3_2.compute_hierarchical_clustering.R"


## Step 3-3: Build MPS-clusters.


# Build MPS-clusters through hierarchical clustering with complete-linkage.
rule compute_MPS_clustering:
    input:
        hierachical_clustering = hierarchical_clustering_directory + "e_value_{e_value}_cov_mode_{cov_mode}_min_cov_{min_cov}_min_seq_id_{min_seq_id}/hierarchical_clustering.RDS"
    output:
        Lincomb_MPS_cluster_links = MPS_clusters_directory + "e_value_{e_value}_cov_mode_{cov_mode}_min_cov_{min_cov}_min_seq_id_{min_seq_id}/delta_{delta}/Lincomb_MPS_cluster_links.csv",
    params:
        delta = "{delta}",
        cores = workflow.cores
    conda:
        "envs/R_env.yaml"
    script:
        "scripts/3_3.build_MPS-clusters.R"


## Step 3-4: Gather genome cascading links.


# Gather cascading genome clusterings into one single file.
rule gather_cascading_links:
    input:
        gen_Lincomb_links = Lincombination_matrix_directory + "e_value_{e_value}_cov_mode_{cov_mode}_min_cov_{min_cov}_min_seq_id_{min_seq_id}/gen_Lincomb_links.csv",
        Lincomb_MPS_cluster_links = MPS_clusters_directory + "e_value_{e_value}_cov_mode_{cov_mode}_min_cov_{min_cov}_min_seq_id_{min_seq_id}/delta_{delta}/Lincomb_MPS_cluster_links.csv"
    output:
        genome_cascading_links = genome_cascading_links_directory + "e_value_{e_value}_cov_mode_{cov_mode}_min_cov_{min_cov}_min_seq_id_{min_seq_id}/delta_{delta}/genome_cascading_links.csv",
    params:
        cores = workflow.cores
    conda:
        "envs/R_env.yaml"
    script:
        "scripts/3_4.gather_cascading_links.R"


## Step 4: Select MPS-representatives.

# Select one MPS-representative genome per MPS-cluster.
rule select_MPS_representatives:
    input:
        genome_index = input_directory + "genome_index.csv",
        Lincombination_matrix = Lincombination_matrix_directory + "e_value_{e_value}_cov_mode_{cov_mode}_min_cov_{min_cov}_min_seq_id_{min_seq_id}/Lincombination_matrix.csv",
        genome_cascading_links = genome_cascading_links_directory + "e_value_{e_value}_cov_mode_{cov_mode}_min_cov_{min_cov}_min_seq_id_{min_seq_id}/delta_{delta}/genome_cascading_links.csv"
    output:
        MPS_representatives = MPS_results_directory + "e_value_{e_value}_cov_mode_{cov_mode}_min_cov_{min_cov}_min_seq_id_{min_seq_id}/delta_{delta}/MPS_representatives.csv",
        MPS_links = MPS_results_directory + "e_value_{e_value}_cov_mode_{cov_mode}_min_cov_{min_cov}_min_seq_id_{min_seq_id}/delta_{delta}/MPS_links.csv"
    params:
        cores = workflow.cores
    conda:
        "envs/R_env.yaml"
    script:
        "scripts/4.choose_MPS-representatives.R"
